{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c87ebeb-a2f2-478b-ae72-dbe160fb555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from model import UNET\n",
    "from utils import (\n",
    "    load_checkpoint,\n",
    "    save_checkpoint,\n",
    "    get_loaders,\n",
    "    check_accuracy,\n",
    "    save_predictions_as_imgs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e11ab1b-4e85-4fac-a6ac-db01d6d56d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size = 16\n",
    "num_epochs = 3\n",
    "image_height = 160\n",
    "image_width = 240\n",
    "load_model = True\n",
    "train_img_dir = \"./Dataset/train\"\n",
    "train_mask_dir = \"./Dataset/train_masks\"\n",
    "val_img_dir = \"./Dataset/val\"\n",
    "val_mask_dir = \"./Dataset/val_masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b47fee-7126-475c-8f92-d6e116426444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn):\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    for batch_index, (data, targets) in enumerate(loop):\n",
    "        targets = targets.float().unsqueeze(1)\n",
    "\n",
    "        #forward\n",
    "        predictions = model(data)\n",
    "        loss = loss_fn(predictions, targets)\n",
    "\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        #update\n",
    "        with torch.no_grad():\n",
    "            optimizer.step()\n",
    "        \n",
    "\n",
    "        # update tqdm loop\n",
    "        loop.set_postfix(loss = loss.item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae664d1-5d4a-4d6b-9aa4-9c9d388d5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(height=image_height, width=image_width),\n",
    "            A.Rotate(limit = 35, p = 1.0),\n",
    "            A.HorizontalFlip(p = 0.5),\n",
    "            A.VerticalFlip(p = 0.1),\n",
    "            A.Normalize(\n",
    "                mean = [0.0, 0.0, 0.0],\n",
    "                std = [1.0, 1.0, 1.0],\n",
    "                max_pixel_value = 255.0\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    val_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(height=image_height, width=image_width),\n",
    "            A.Normalize(\n",
    "                mean = [0.0, 0.0, 0.0],\n",
    "                std = [1.0, 1.0, 1.0],\n",
    "                max_pixel_value = 255.0\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "    )        \n",
    "\n",
    "    model = UNET(in_channels=3, out_channels=1)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_loader, val_loader = get_loaders(\n",
    "        train_img_dir,\n",
    "        train_mask_dir,\n",
    "        val_img_dir,\n",
    "        val_mask_dir,\n",
    "        batch_size,\n",
    "        train_transform,\n",
    "        val_transform\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_fn(train_loader, model, optimizer, loss_fn)\n",
    "        \n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict()\n",
    "        }\n",
    "        save_checkpoint(checkpoint)\n",
    "        \n",
    "        check_accuracy(val_loader, model)\n",
    "        \n",
    "        save_predictions_as_imgs(\n",
    "            val_loader, model, folder=\"saved_images/\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f1a5f68-8fcf-43bc-bcfc-bb81ae54c641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 255/255 [53:46<00:00, 12.65s/it, loss=<built-in method item of Tensor object at 0x0000016E2921BA20>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Got 38680904/39052800 with acc 99.05\n",
      "Dice score: 0.9774115085601807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 255/255 [50:58<00:00, 11.99s/it, loss=<built-in method item of Tensor object at 0x0000016E2D897E30>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Got 38751381/39052800 with acc 99.23\n",
      "Dice score: 0.9818095564842224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 255/255 [53:46<00:00, 12.65s/it, loss=<built-in method item of Tensor object at 0x0000016E2D897C00>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Got 38772860/39052800 with acc 99.28\n",
      "Dice score: 0.9831939339637756\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
